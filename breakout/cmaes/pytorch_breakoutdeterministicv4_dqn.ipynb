{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed61b0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting BindsNET@ git+https://github.com/BindsNET/bindsnet.git@ead55217e05ba4c6ef27f45ff5dc7d61b4abaa13\n",
      "  Cloning https://github.com/BindsNET/bindsnet.git (to revision ead55217e05ba4c6ef27f45ff5dc7d61b4abaa13) to /private/var/folders/j_/ygb_gxx970b1bfpk3v12gc980000gp/T/pip-install-jzhzxux7/bindsnet_1bb991471f55493b908504b71d2a24ec\n",
      "  Running command git clone -q https://github.com/BindsNET/bindsnet.git /private/var/folders/j_/ygb_gxx970b1bfpk3v12gc980000gp/T/pip-install-jzhzxux7/bindsnet_1bb991471f55493b908504b71d2a24ec\n",
      "  Running command git rev-parse -q --verify 'sha^ead55217e05ba4c6ef27f45ff5dc7d61b4abaa13'\n",
      "  Running command git fetch -q https://github.com/BindsNET/bindsnet.git ead55217e05ba4c6ef27f45ff5dc7d61b4abaa13\n",
      "  Running command git checkout -q ead55217e05ba4c6ef27f45ff5dc7d61b4abaa13\n",
      "Collecting gym@ git+https://github.com/openai/gym.git@a5a6ae6bc0a5cfc0ff1ce9be723d59593c165022\n",
      "  Cloning https://github.com/openai/gym.git (to revision a5a6ae6bc0a5cfc0ff1ce9be723d59593c165022) to /private/var/folders/j_/ygb_gxx970b1bfpk3v12gc980000gp/T/pip-install-jzhzxux7/gym_dbac3c0e29e8426d8709ee7cb86fb825\n",
      "  Running command git clone -q https://github.com/openai/gym.git /private/var/folders/j_/ygb_gxx970b1bfpk3v12gc980000gp/T/pip-install-jzhzxux7/gym_dbac3c0e29e8426d8709ee7cb86fb825\n",
      "  Running command git rev-parse -q --verify 'sha^a5a6ae6bc0a5cfc0ff1ce9be723d59593c165022'\n",
      "  Running command git fetch -q https://github.com/openai/gym.git a5a6ae6bc0a5cfc0ff1ce9be723d59593c165022\n",
      "  Running command git checkout -q a5a6ae6bc0a5cfc0ff1ce9be723d59593c165022\n",
      "Collecting appdirs==1.4.4\n",
      "  Using cached appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting atari-py==0.2.6\n",
      "  Using cached atari_py-0.2.6-cp39-cp39-macosx_11_0_x86_64.whl\n",
      "Requirement already satisfied: attrs==20.3.0 in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from -r ../../requirements.txt (line 3)) (20.3.0)\n",
      "Collecting box2d-py==2.3.8\n",
      "  Using cached box2d_py-2.3.8-cp39-cp39-macosx_11_0_x86_64.whl\n",
      "Requirement already satisfied: cffi==1.14.5 in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from -r ../../requirements.txt (line 6)) (1.14.5)\n",
      "Collecting cloudpickle==1.2.2\n",
      "  Using cached cloudpickle-1.2.2-py2.py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: cycler==0.10.0 in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from -r ../../requirements.txt (line 8)) (0.10.0)\n",
      "Collecting Cython==0.29.23\n",
      "  Using cached Cython-0.29.23-cp39-cp39-macosx_10_9_x86_64.whl (1.9 MB)\n",
      "Collecting decorator==4.4.2\n",
      "  Using cached decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
      "Collecting distlib==0.3.1\n",
      "  Using cached distlib-0.3.1-py2.py3-none-any.whl (335 kB)\n",
      "Collecting distro==1.5.0\n",
      "  Using cached distro-1.5.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting fasteners==0.16\n",
      "  Using cached fasteners-0.16-py2.py3-none-any.whl (28 kB)\n",
      "Collecting filelock==3.0.12\n",
      "  Using cached filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
      "Collecting glfw==2.1.0\n",
      "  Using cached glfw-2.1.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-macosx_10_6_intel.whl (99 kB)\n",
      "Collecting imageio==2.9.0\n",
      "  Using cached imageio-2.9.0-py3-none-any.whl (3.3 MB)\n",
      "Collecting iniconfig==1.1.1\n",
      "  Using cached iniconfig-1.1.1-py2.py3-none-any.whl (5.0 kB)\n",
      "Collecting joblib==1.0.1\n",
      "  Using cached joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "Collecting kiwisolver==1.3.1\n",
      "  Using cached kiwisolver-1.3.1-cp39-cp39-macosx_10_9_x86_64.whl (61 kB)\n",
      "Collecting matplotlib==3.4.1\n",
      "  Using cached matplotlib-3.4.1-cp39-cp39-macosx_10_9_x86_64.whl (7.2 MB)\n",
      "Collecting mujoco-py==2.0.2.13\n",
      "  Using cached mujoco_py-2.0.2.13-py3-none-any.whl\n",
      "Collecting networkx==2.5.1\n",
      "  Using cached networkx-2.5.1-py3-none-any.whl (1.6 MB)\n",
      "Collecting numpy==1.20.2\n",
      "  Using cached numpy-1.20.2-cp39-cp39-macosx_10_9_x86_64.whl (16.1 MB)\n",
      "Collecting opencv-python==4.5.1.48\n",
      "  Using cached opencv_python-4.5.1.48-cp39-cp39-macosx_10_13_x86_64.whl (40.3 MB)\n",
      "Requirement already satisfied: packaging==20.9 in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from -r ../../requirements.txt (line 26)) (20.9)\n",
      "Collecting pandas==1.2.4\n",
      "  Using cached pandas-1.2.4-cp39-cp39-macosx_10_9_x86_64.whl (10.7 MB)\n",
      "Collecting pbr==5.6.0\n",
      "  Using cached pbr-5.6.0-py2.py3-none-any.whl (111 kB)\n",
      "Collecting Pillow==8.2.0\n",
      "  Using cached Pillow-8.2.0-cp39-cp39-macosx_10_10_x86_64.whl (2.8 MB)\n",
      "Collecting pluggy==0.13.1\n",
      "  Using cached pluggy-0.13.1-py2.py3-none-any.whl (18 kB)\n",
      "Collecting protobuf==3.15.8\n",
      "  Using cached protobuf-3.15.8-cp39-cp39-macosx_10_9_x86_64.whl (1.0 MB)\n",
      "Collecting py==1.10.0\n",
      "  Using cached py-1.10.0-py2.py3-none-any.whl (97 kB)\n",
      "Collecting pybullet==3.1.6\n",
      "  Using cached pybullet-3.1.6-cp39-cp39-macosx_11_0_x86_64.whl\n",
      "Requirement already satisfied: pycparser==2.20 in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from -r ../../requirements.txt (line 34)) (2.20)\n",
      "Collecting pyglet==1.5.11\n",
      "  Using cached pyglet-1.5.11-py3-none-any.whl (1.1 MB)\n",
      "Requirement already satisfied: pyparsing==2.4.7 in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from -r ../../requirements.txt (line 36)) (2.4.7)\n",
      "Collecting pytest==6.2.3\n",
      "  Using cached pytest-6.2.3-py3-none-any.whl (280 kB)\n",
      "Requirement already satisfied: python-dateutil==2.8.1 in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from -r ../../requirements.txt (line 38)) (2.8.1)\n",
      "Requirement already satisfied: pytz==2021.1 in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from -r ../../requirements.txt (line 39)) (2021.1)\n",
      "Collecting PyWavelets==1.1.1\n",
      "  Using cached PyWavelets-1.1.1-cp39-cp39-macosx_10_9_x86_64.whl (4.3 MB)\n",
      "Collecting scikit-build==0.11.1\n",
      "  Using cached scikit_build-0.11.1-py2.py3-none-any.whl (72 kB)\n",
      "Collecting scikit-image==0.18.1\n",
      "  Using cached scikit_image-0.18.1-cp39-cp39-macosx_10_9_x86_64.whl (12.9 MB)\n",
      "Collecting scikit-learn==0.24.1\n",
      "  Using cached scikit_learn-0.24.1-cp39-cp39-macosx_10_13_x86_64.whl (7.3 MB)\n",
      "Collecting scipy==1.6.3\n",
      "  Using cached scipy-1.6.3-cp39-cp39-macosx_10_9_x86_64.whl (30.9 MB)\n",
      "Requirement already satisfied: six==1.15.0 in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from -r ../../requirements.txt (line 45)) (1.15.0)\n",
      "Collecting stevedore==3.3.0\n",
      "  Using cached stevedore-3.3.0-py3-none-any.whl (49 kB)\n",
      "Collecting tensorboardX==2.2\n",
      "  Using cached tensorboardX-2.2-py2.py3-none-any.whl (120 kB)\n",
      "Collecting threadpoolctl==2.1.0\n",
      "  Using cached threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Collecting tifffile==2021.4.8\n",
      "  Using cached tifffile-2021.4.8-py3-none-any.whl (165 kB)\n",
      "Collecting toml==0.10.2\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Collecting torch==1.8.1\n",
      "  Using cached torch-1.8.1-cp39-none-macosx_10_9_x86_64.whl (119.6 MB)\n",
      "Collecting torchvision==0.9.1\n",
      "  Using cached torchvision-0.9.1-cp39-cp39-macosx_10_9_x86_64.whl (13.1 MB)\n",
      "Collecting tqdm==4.60.0\n",
      "  Using cached tqdm-4.60.0-py2.py3-none-any.whl (75 kB)\n",
      "Collecting typing-extensions==3.7.4.3\n",
      "  Using cached typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting virtualenv==20.4.4\n",
      "  Using cached virtualenv-20.4.4-py2.py3-none-any.whl (7.2 MB)\n",
      "Collecting virtualenv-clone==0.5.4\n",
      "  Using cached virtualenv_clone-0.5.4-py2.py3-none-any.whl (6.6 kB)\n",
      "Collecting virtualenvwrapper==4.8.4\n",
      "  Using cached virtualenvwrapper-4.8.4-py2.py3-none-any.whl\n",
      "Requirement already satisfied: setuptools>=28.0.0 in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from scikit-build==0.11.1->-r ../../requirements.txt (line 41)) (54.2.0)\n",
      "Requirement already satisfied: wheel>=0.29.0 in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from scikit-build==0.11.1->-r ../../requirements.txt (line 41)) (0.36.2)\n",
      "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'atari-py' candidate (version 0.2.6 at https://files.pythonhosted.org/packages/43/dd/2721f34a89dc520d2e09363fd23d110a33bbab2399e50fdced6eb2ed2157/atari-py-0.2.6.tar.gz#sha256=6249ad5079b0489e87eb44e65485bb1b07cc1b5af729f1ee52ece749503ceb1d (from https://pypi.org/simple/atari-py/))\n",
      "Reason for being yanked: re-release with new wheels\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building wheels for collected packages: BindsNET, gym\n",
      "  Building wheel for BindsNET (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for BindsNET: filename=BindsNET-0.2.9-py3-none-any.whl size=99006 sha256=71ab8cc792aab74293295be81475041a556d6080a276d9ae9ae5c4fec84e51f9\n",
      "  Stored in directory: /Users/camiloortiz/Library/Caches/pip/wheels/79/77/1c/7de963265cf055221c577a1a3e307cf596b4a087fa4f7b549c\n",
      "  Building wheel for gym (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gym: filename=gym-0.18.0-py3-none-any.whl size=1657516 sha256=93dd8cbba97f708289b7d08e30d152013405602a2fa9ca02a49bb08b6aeaf545\n",
      "  Stored in directory: /Users/camiloortiz/Library/Caches/pip/wheels/03/60/7f/33b8247a99209a2e0c1e977a24fa050c4d7859a6352f16a904\n",
      "Successfully built BindsNET gym\n",
      "Installing collected packages: typing-extensions, Pillow, numpy, kiwisolver, decorator, torch, toml, tifffile, threadpoolctl, scipy, PyWavelets, pyglet, py, protobuf, pluggy, pbr, networkx, matplotlib, joblib, iniconfig, imageio, filelock, distro, distlib, cloudpickle, appdirs, virtualenv-clone, virtualenv, tqdm, torchvision, tensorboardX, stevedore, scikit-learn, scikit-image, scikit-build, pytest, pandas, opencv-python, gym, glfw, fasteners, Cython, virtualenvwrapper, pybullet, mujoco-py, box2d-py, BindsNET, atari-py\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.10.0.2\n",
      "    Uninstalling typing-extensions-3.10.0.2:\n",
      "      Successfully uninstalled typing-extensions-3.10.0.2\n",
      "  Attempting uninstall: Pillow\n",
      "    Found existing installation: Pillow 8.3.2\n",
      "    Uninstalling Pillow-8.3.2:\n",
      "      Successfully uninstalled Pillow-8.3.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.2\n",
      "    Uninstalling numpy-1.21.2:\n",
      "      Successfully uninstalled numpy-1.21.2\n",
      "  Attempting uninstall: kiwisolver\n",
      "    Found existing installation: kiwisolver 1.3.2\n",
      "    Uninstalling kiwisolver-1.3.2:\n",
      "      Successfully uninstalled kiwisolver-1.3.2\n",
      "  Attempting uninstall: decorator\n",
      "    Found existing installation: decorator 5.0.6\n",
      "    Uninstalling decorator-5.0.6:\n",
      "      Successfully uninstalled decorator-5.0.6\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.9.1\n",
      "    Uninstalling torch-1.9.1:\n",
      "      Successfully uninstalled torch-1.9.1\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.4.3\n",
      "    Uninstalling matplotlib-3.4.3:\n",
      "      Successfully uninstalled matplotlib-3.4.3\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.10.1\n",
      "    Uninstalling torchvision-0.10.1:\n",
      "      Successfully uninstalled torchvision-0.10.1\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.3.3\n",
      "    Uninstalling pandas-1.3.3:\n",
      "      Successfully uninstalled pandas-1.3.3\n",
      "Successfully installed BindsNET-0.2.9 Cython-0.29.23 Pillow-8.2.0 PyWavelets-1.1.1 appdirs-1.4.4 atari-py-0.2.6 box2d-py-2.3.8 cloudpickle-1.2.2 decorator-4.4.2 distlib-0.3.1 distro-1.5.0 fasteners-0.16 filelock-3.0.12 glfw-2.1.0 gym-0.18.0 imageio-2.9.0 iniconfig-1.1.1 joblib-1.0.1 kiwisolver-1.3.1 matplotlib-3.4.1 mujoco-py-2.0.2.13 networkx-2.5.1 numpy-1.20.2 opencv-python-4.5.1.48 pandas-1.2.4 pbr-5.6.0 pluggy-0.13.1 protobuf-3.15.8 py-1.10.0 pybullet-3.1.6 pyglet-1.5.11 pytest-6.2.3 scikit-build-0.11.1 scikit-image-0.18.1 scikit-learn-0.24.1 scipy-1.6.3 stevedore-3.3.0 tensorboardX-2.2 threadpoolctl-2.1.0 tifffile-2021.4.8 toml-0.10.2 torch-1.8.1 torchvision-0.9.1 tqdm-4.60.0 typing-extensions-3.7.4.3 virtualenv-20.4.4 virtualenv-clone-0.5.4 virtualenvwrapper-4.8.4\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/Cellar/jupyterlab/3.0.14/libexec/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r ../../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ff59d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn\n",
    "import numpy as np\n",
    "import random\n",
    "import gym\n",
    "from collections import namedtuple\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple\n",
    "from collections import deque\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51bfc9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Args = namedtuple('Args', ['gamma', 'env', 'n_episode', 'batch_size', 'hidden_dim', 'capacity', 'max_episode', 'min_eps'])\n",
    "FLAGS = Args(gamma=0.99, env='BreakoutDeterministic-v4', n_episode=1000, batch_size=32, hidden_dim=12, capacity=50000, max_episode=1000, min_eps=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6399f6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple(\"Transition\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b6ffea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity: int) -> None:\n",
    "        \"\"\"Replay memory class\n",
    "        \"\"\"\n",
    "        self.capacity = capacity\n",
    "        self.cursor = 0\n",
    "        self.memory = []\n",
    "\n",
    "    def push(self,\n",
    "             state: np.ndarray,\n",
    "             action: int,\n",
    "             reward: int,\n",
    "             next_state: np.ndarray,\n",
    "             done: bool) -> None:\n",
    "        \"\"\"Creates `Transition` and insert\n",
    "        \"\"\"\n",
    "        if len(self) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "\n",
    "        self.memory[self.cursor] = Transition(state,\n",
    "                                              action, reward, next_state, done)\n",
    "        self.cursor = (self.cursor + 1) % self.capacity\n",
    "\n",
    "    def pop(self, batch_size: int) -> List[Transition]:\n",
    "        \"\"\"Returns a randomly sampled minibatch\n",
    "        \"\"\"\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Returns the length \"\"\"\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a83d6e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(torch.nn.Module):\n",
    "    def __init__(self, input_shape: [int], output_dim: int, hidden_dim: int, batch_size: int) -> None:\n",
    "        \"\"\"DQN Network\n",
    "        \"\"\"\n",
    "        super(DQN, self).__init__()\n",
    "        w, h, c = input_shape\n",
    "        kernel_size = 3\n",
    "        padding = 1\n",
    "        stride = 1\n",
    "        out_channels = 3\n",
    "\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=1, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Flatten()\n",
    "        )\n",
    "\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(19200, hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.25)\n",
    "        )\n",
    "\n",
    "        self.final = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_dim, output_dim),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Returns a Q_value\n",
    "        \"\"\"\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.final(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da5197d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ae51ba8458d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \"\"\"Agent class\n\u001b[1;32m      5\u001b[0m         \"\"\"\n",
      "\u001b[0;32m<ipython-input-1-ae51ba8458d8>\u001b[0m in \u001b[0;36mAgent\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_to_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \"\"\"torch.Variable syntax helper\n\u001b[1;32m     15\u001b[0m         \"\"\"\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "class Agent(object):\n",
    "\n",
    "    def __init__(self, input_shape: [int], output_dim: int, hidden_dim: int, batch_size: int) -> None:\n",
    "        \"\"\"Agent class\n",
    "        \"\"\"\n",
    "        self.dqn = DQN(input_shape, output_dim, hidden_dim, batch_size)\n",
    "        self.input_dim = input_shape\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.loss_fn = torch.nn.MSELoss()\n",
    "        self.optim = torch.optim.Adam(self.dqn.parameters())\n",
    "\n",
    "    def _to_variable(self, x: np.ndarray) -> torch.Tensor:\n",
    "        \"\"\"torch.Variable syntax helper\n",
    "        \"\"\"\n",
    "        return torch.autograd.Variable(torch.Tensor(x))\n",
    "\n",
    "    def get_action(self, states: np.ndarray, eps: float) -> int:\n",
    "        \"\"\"Returns an action\n",
    "        \"\"\"\n",
    "        if np.random.rand() < eps:\n",
    "            return np.random.choice(self.output_dim)\n",
    "        else:\n",
    "            self.dqn.train(mode=False)\n",
    "            scores = self.get_Q(np.array([states]))\n",
    "            _, argmax = torch.max(scores.data, 1)\n",
    "            return int(argmax.numpy())\n",
    "\n",
    "    def get_Q(self, states: np.ndarray) -> torch.FloatTensor:\n",
    "        \"\"\"Returns `Q-value`\n",
    "        \"\"\"\n",
    "        states = self._to_variable(states)\n",
    "        self.dqn.train(mode=False)\n",
    "\n",
    "        return self.dqn(states)\n",
    "\n",
    "    def train(self, Q_pred: torch.FloatTensor, Q_true: torch.FloatTensor) -> float:\n",
    "        \"\"\"Computes `loss` and backpropagation\n",
    "        \"\"\"\n",
    "        self.dqn.train(mode=True)\n",
    "        self.optim.zero_grad()\n",
    "        loss = self.loss_fn(Q_pred, Q_true)\n",
    "        loss.backward()\n",
    "        self.optim.step()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bdda9e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-08700d055e06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \"\"\"Preprocesses gym state\n\u001b[1;32m      3\u001b[0m     \"\"\"\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Crop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m34\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m194\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m160\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "def preprocess(states: np.ndarray):\n",
    "    \"\"\"Preprocesses gym state\n",
    "    \"\"\"\n",
    "    # Crop\n",
    "    states = states[34:194, 0:160, :]\n",
    "\n",
    "    # Convert to grayscale\n",
    "    states = cv2.cvtColor(states, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Subsample to 80x80\n",
    "    states = cv2.resize(states, (80, 80))\n",
    "    states = cv2.threshold(states, 0, 1, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "    states = states.reshape(1, states.shape[0], states.shape[1])\n",
    "    return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbd47a7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-2a23565d6666>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAgent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminibatch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTransition\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \"\"\" Train on minibatch data\n\u001b[1;32m      3\u001b[0m     \"\"\"\n\u001b[1;32m      4\u001b[0m     \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mminibatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mminibatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Agent' is not defined"
     ]
    }
   ],
   "source": [
    "def train_helper(agent: Agent, minibatch: List[Transition], gamma: float) -> float:\n",
    "    \"\"\" Train on minibatch data\n",
    "    \"\"\"\n",
    "    states = np.array([x.state for x in minibatch])\n",
    "    actions = np.array([x.action for x in minibatch])\n",
    "    rewards = np.array([x.reward for x in minibatch])\n",
    "    next_states = np.array([x.next_state for x in minibatch])\n",
    "    Q_predict = agent.get_Q(states)\n",
    "    Q_target = Q_predict.clone().data.numpy()\n",
    "    Q_target[np.arange(len(Q_target)), actions] = rewards + gamma * np.max(agent.get_Q(next_states).data.numpy(),\n",
    "                                                                           axis=1)\n",
    "    Q_target = agent._to_variable(Q_target)\n",
    "\n",
    "    return agent.train(Q_predict, Q_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf5ff1c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gym' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-aff9b67d150a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m def play_episode(env: gym.Env,\n\u001b[0m\u001b[1;32m      2\u001b[0m                  \u001b[0magent\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAgent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                  \u001b[0mreplay_memory\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mReplayMemory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                  \u001b[0meps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                  batch_size: int) -> int:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gym' is not defined"
     ]
    }
   ],
   "source": [
    "def play_episode(env: gym.Env,\n",
    "                 agent: Agent,\n",
    "                 replay_memory: ReplayMemory,\n",
    "                 eps: float,\n",
    "                 batch_size: int) -> int:\n",
    "    \"\"\"Play an episode\n",
    "    \"\"\"\n",
    "    s = env.reset()\n",
    "    s = preprocess(s)\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        a = agent.get_action(s, eps)\n",
    "        s2, r, done, info = env.step(a)\n",
    "        env.render()\n",
    "\n",
    "        # Preprocessing step\n",
    "        s2 = preprocess(s2)\n",
    "        r = clip_reward(r)\n",
    "\n",
    "        total_reward += r\n",
    "\n",
    "        if done:\n",
    "            r = -1\n",
    "        replay_memory.push(s, a, r, s2, done)\n",
    "\n",
    "        if len(replay_memory) > batch_size:\n",
    "            minibatch = replay_memory.pop(batch_size)\n",
    "            train_helper(agent, minibatch, FLAGS.gamma)\n",
    "\n",
    "        s = s2\n",
    "\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "792f2877",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gym' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2e49772fa83c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mget_env_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \"\"\"Returns input_dim & output_dim\n\u001b[1;32m      3\u001b[0m     \"\"\"\n\u001b[1;32m      4\u001b[0m     \u001b[0minput_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moutput_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gym' is not defined"
     ]
    }
   ],
   "source": [
    "def get_env_dim(env: gym.Env) -> Tuple[int, int]:\n",
    "    \"\"\"Returns input_dim & output_dim\n",
    "    \"\"\"\n",
    "    input_dim = env.observation_space.shape\n",
    "    output_dim = env.action_space.n\n",
    "\n",
    "    return input_dim, output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06faa7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_annealing(epsiode: int, max_episode: int, min_eps: float) -> float:\n",
    "    \"\"\"Returns ùú∫ for ùú∫-annealing\n",
    "    1.0---|\\\n",
    "          | \\\n",
    "          |  \\\n",
    "    min_e +---+------->\n",
    "              |\n",
    "              max_episode\n",
    "    \"\"\"\n",
    "\n",
    "    slope = (min_eps - 1.0) / max_episode\n",
    "    return max(slope * epsiode + 1.0, min_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc882a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_reward(reward):\n",
    "    \"\"\"Clip reward so that it's in [-1, 1]\n",
    "    \"\"\"\n",
    "    if reward < -1:\n",
    "        reward = -1\n",
    "    elif reward > 1:\n",
    "        reward = 1\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e76575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Episode:     1] Reward:   3.0 ùú∫-greedy:  1.00\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    env = gym.make(FLAGS.env)\n",
    "    env = gym.wrappers.Monitor(env, directory=\"monitors\", force=True)\n",
    "\n",
    "    average_rewards = []\n",
    "    q = deque(maxlen=100)\n",
    "\n",
    "    input_dim, output_dim = get_env_dim(env)\n",
    "\n",
    "    agent = Agent((80, 80, 1) , output_dim, FLAGS.hidden_dim, FLAGS.batch_size)\n",
    "    replay_memory = ReplayMemory(FLAGS.capacity)\n",
    "\n",
    "    for i in range(FLAGS.n_episode):\n",
    "        eps = epsilon_annealing(i, FLAGS.max_episode, FLAGS.min_eps)\n",
    "        r = play_episode(env, agent, replay_memory, eps, FLAGS.batch_size)\n",
    "        print(\"[Episode: {:5}] Reward: {:5} ùú∫-greedy: {:5.2f}\".format(i + 1, r, eps))\n",
    "\n",
    "        q.append(r)\n",
    "        if i % 100 == 0:\n",
    "            average_rewards.append(mean(q))\n",
    "\n",
    "    name = \"DQN-cnn-{}-{}-{}-reward_clamping\".format(FLAGS.env, FLAGS.n_episode, FLAGS.gamma)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(average_rewards)\n",
    "\n",
    "    ax.set(xlabel='Episode', ylabel='Reward',\n",
    "           title='DQN (CNN) performance on {}'.format(FLAGS.env))\n",
    "    plt.show()\n",
    "\n",
    "finally:\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ac658d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
