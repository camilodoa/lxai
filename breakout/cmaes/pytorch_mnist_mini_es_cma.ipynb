{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (1.8.1)\n",
      "Requirement already satisfied: numpy in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from torch) (1.20.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from torch) (3.7.4.3)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/Cellar/jupyterlab/3.0.14/libexec/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torchvision in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (0.9.1)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from torchvision) (8.2.0)\n",
      "Requirement already satisfied: numpy in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from torchvision) (1.20.2)\n",
      "Requirement already satisfied: torch==1.8.1 in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from torchvision) (1.8.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from torch==1.8.1->torchvision) (3.7.4.3)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/Cellar/jupyterlab/3.0.14/libexec/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: cma in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (3.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/Cellar/jupyterlab/3.0.14/libexec/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-7.6.5-py2.py3-none-any.whl (121 kB)\n",
      "\u001b[K     |████████████████████████████████| 121 kB 7.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: ipykernel>=4.5.1 in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from ipywidgets) (5.5.3)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from ipywidgets) (7.22.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from ipywidgets) (5.0.5)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from ipywidgets) (5.1.3)\n",
      "Collecting jupyterlab-widgets>=1.0.0\n",
      "  Downloading jupyterlab_widgets-1.0.2-py3-none-any.whl (243 kB)\n",
      "\u001b[K     |████████████████████████████████| 243 kB 27.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting widgetsnbextension~=3.5.0\n",
      "  Downloading widgetsnbextension-3.5.2-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 28.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: appnope in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: tornado>=4.2 in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: jupyter-client in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets) (54.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: decorator in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
      "Requirement already satisfied: pickleshare in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt_toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets) (3.0.18)\n",
      "Requirement already satisfied: pygments in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets) (2.8.1)\n",
      "Requirement already satisfied: backcall in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.2)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from nbformat>=4.2.0->ipywidgets) (3.2.0)\n",
      "Requirement already satisfied: jupyter_core in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from nbformat>=4.2.0->ipywidgets) (4.7.1)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.17.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (20.3.0)\n",
      "Requirement already satisfied: six>=1.11.0 in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (1.15.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from prompt_toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from widgetsnbextension~=3.5.0->ipywidgets) (6.3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.11.3)\n",
      "Requirement already satisfied: pyzmq>=17 in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (22.0.3)\n",
      "Requirement already satisfied: argon2-cffi in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (20.1.0)\n",
      "Requirement already satisfied: nbconvert in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (6.0.7)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.9.4)\n",
      "Requirement already satisfied: prometheus_client in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.10.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cffi>=1.0.0 in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.14.5)\n",
      "Requirement already satisfied: pycparser in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.20)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: jupyterlab_pygments in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.3)\n",
      "Requirement already satisfied: bleach in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.3.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.4.3)\n",
      "Requirement already satisfied: testpath in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.4.4)\n",
      "Requirement already satisfied: defusedxml in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.3)\n",
      "Requirement already satisfied: async-generator in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.10)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: packaging in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (20.9)\n",
      "Requirement already satisfied: webencodings in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.4.7)\n",
      "Installing collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\n",
      "Successfully installed ipywidgets-7.6.5 jupyterlab-widgets-1.0.2 widgetsnbextension-3.5.2\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/Cellar/jupyterlab/3.0.14/libexec/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch\n",
    "%pip install torchvision\n",
    "%pip install cma\n",
    "%pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import multiprocessing as mp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from collections import namedtuple\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "import os.path\n",
    "import errno\n",
    "import codecs\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.device_count() 0\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "print(\"torch.cuda.device_count()\", torch.cuda.device_count())\n",
    "# print(\"torch.cuda.current_device()\", torch.cuda.current_device())\n",
    "# torch.cuda.set_device(3)\n",
    "# print(\"torch.cuda.current_device()\", torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ranks(x):\n",
    "  \"\"\"\n",
    "  Returns ranks in [0, len(x))\n",
    "  Note: This is different from scipy.stats.rankdata, which returns ranks in [1, len(x)].\n",
    "  (https://github.com/openai/evolution-strategies-starter/blob/master/es_distributed/es.py)\n",
    "  \"\"\"\n",
    "  assert x.ndim == 1\n",
    "  ranks = np.empty(len(x), dtype=int)\n",
    "  ranks[x.argsort()] = np.arange(len(x))\n",
    "  return ranks\n",
    "\n",
    "def compute_centered_ranks(x):\n",
    "  \"\"\"\n",
    "  https://github.com/openai/evolution-strategies-starter/blob/master/es_distributed/es.py\n",
    "  \"\"\"\n",
    "  y = compute_ranks(x.ravel()).reshape(x.shape).astype(np.float32)\n",
    "  y /= (x.size - 1)\n",
    "  y -= .5\n",
    "  return y\n",
    "\n",
    "def compute_weight_decay(weight_decay, model_param_list):\n",
    "  model_param_grid = np.array(model_param_list)\n",
    "  return - weight_decay * np.mean(model_param_grid * model_param_grid, axis=1)\n",
    "\n",
    "class CMAES:\n",
    "  '''CMA-ES wrapper.'''\n",
    "  def __init__(self, num_params,      # number of model parameters\n",
    "               sigma_init=0.10,       # initial standard deviation\n",
    "               popsize=255):          # population size\n",
    "\n",
    "    self.num_params = num_params\n",
    "    self.sigma_init = sigma_init\n",
    "    self.popsize = popsize\n",
    "\n",
    "    self.solutions = None\n",
    "\n",
    "    import cma\n",
    "    self.es = cma.CMAEvolutionStrategy( self.num_params * [0],\n",
    "                                        self.sigma_init,\n",
    "                                        {'popsize': self.popsize})\n",
    "\n",
    "  def rms_stdev(self):\n",
    "    sigma = self.es.result[6]\n",
    "    return np.mean(np.sqrt(sigma*sigma))\n",
    "\n",
    "  def ask(self):\n",
    "    '''returns a list of parameters'''\n",
    "    self.solutions = np.array(self.es.ask())\n",
    "    return self.solutions\n",
    "\n",
    "  def tell(self, reward_table_result):\n",
    "    reward_table = reward_table_result\n",
    "    self.es.tell(self.solutions, (-reward_table).tolist()) # convert minimizer to maximizer.\n",
    "\n",
    "  def done(self):\n",
    "    return self.es.stop()\n",
    "\n",
    "  def current_param(self):\n",
    "    return self.es.result[5] # mean solution, presumably better with noise\n",
    "  \n",
    "  def best_param(self):\n",
    "    return self.es.result[0] # best evaluated solution\n",
    "\n",
    "  def result(self): # return best params so far, along with historically best reward, curr reward, sigma\n",
    "    r = self.es.result\n",
    "    return (r[0], -r[1], -r[1], r[6])\n",
    "\n",
    "class SimpleES:\n",
    "  '''Simple Evolution Strategies.'''\n",
    "  def __init__(self, num_params,      # number of model parameters\n",
    "               sigma_init=0.10,       # initial standard deviation\n",
    "               sigma_alpha=0.20,      # learning rate for standard deviation\n",
    "               sigma_decay=0.999,     # anneal standard deviation\n",
    "               sigma_limit=0.01,      # stop annealing if less than this\n",
    "               popsize=255,           # population size\n",
    "               elite_ratio=0.1,       # percentage of the elites\n",
    "               done_threshold=1e-6,   # threshold when we say we are done\n",
    "               average_baseline=True, # set baseline to average of batch\n",
    "               forget_best=True):     # only use the best from latest generation\n",
    "\n",
    "    self.num_params = num_params\n",
    "    self.sigma_init = sigma_init\n",
    "    self.sigma_alpha = sigma_alpha\n",
    "    self.sigma_decay = sigma_decay\n",
    "    self.sigma_limit = sigma_limit\n",
    "    self.popsize = popsize\n",
    "    self.average_baseline = average_baseline\n",
    "    if self.average_baseline:\n",
    "      assert (self.popsize & 2), \"Population size must be even\"\n",
    "      self.batch_size = int(self.popsize / 2)\n",
    "    else:\n",
    "      assert (self.popsize & 1), \"Population size must be odd\"\n",
    "      self.batch_size = int((self.popsize - 1) / 2)\n",
    "    self.elite_ratio = elite_ratio\n",
    "    self.elite_popsize = int(self.popsize * self.elite_ratio)\n",
    "    self.forget_best = forget_best\n",
    "    self.batch_reward = np.zeros(self.batch_size * 2)\n",
    "    self.mu = np.zeros(self.num_params)\n",
    "    self.sigma = np.ones(self.num_params) * self.sigma_init\n",
    "    self.curr_best_mu = np.zeros(self.num_params)\n",
    "    self.best_mu = np.zeros(self.num_params)\n",
    "    self.best_reward = 0\n",
    "    self.first_interation = True\n",
    "    self.done_threshold = done_threshold\n",
    "\n",
    "  def rms_stdev(self):\n",
    "    sigma = self.sigma\n",
    "    return np.mean(np.sqrt(sigma*sigma))\n",
    "\n",
    "  def ask(self):\n",
    "    '''returns a list of parameters'''\n",
    "    # antithetic sampling\n",
    "    self.epsilon = np.random.randn(self.batch_size, self.num_params) * self.sigma.reshape(1, self.num_params)\n",
    "    self.epsilon_full = np.concatenate([self.epsilon, - self.epsilon])\n",
    "    if self.average_baseline:\n",
    "      epsilon = self.epsilon_full\n",
    "    else:\n",
    "      # first population is mu, then positive epsilon, then negative epsilon\n",
    "      epsilon = np.concatenate([np.zeros((1, self.num_params)), self.epsilon_full])\n",
    "    solutions = self.mu.reshape(1, self.num_params) + epsilon\n",
    "    return solutions\n",
    "\n",
    "  def tell(self, reward_table_result):\n",
    "    # input must be a numpy float array\n",
    "    assert(len(reward_table_result) == self.popsize), \"Inconsistent reward_table size reported.\"\n",
    "\n",
    "    reward_table = reward_table_result\n",
    "\n",
    "    reward_offset = 1\n",
    "    if self.average_baseline:\n",
    "      b = np.mean(reward_table)\n",
    "      reward_offset = 0\n",
    "    else:\n",
    "      b = reward_table[0] # baseline\n",
    "      \n",
    "    reward = reward_table[reward_offset:]\n",
    "    idx = np.argsort(reward)[::-1][0:self.elite_popsize]\n",
    "\n",
    "    best_reward = reward[idx[0]]\n",
    "    if (best_reward > b or self.average_baseline):\n",
    "      best_mu = self.mu + self.epsilon_full[idx[0]]\n",
    "      best_reward = reward[idx[0]]\n",
    "    else:\n",
    "      best_mu = self.mu\n",
    "      best_reward = b\n",
    "\n",
    "    self.curr_best_reward = best_reward\n",
    "    self.curr_best_mu = best_mu\n",
    "\n",
    "    if self.first_interation:\n",
    "      self.first_interation = False\n",
    "      self.best_reward = self.curr_best_reward\n",
    "      self.best_mu = best_mu\n",
    "    else:\n",
    "      if self.forget_best or (self.curr_best_reward > self.best_reward):\n",
    "        self.best_mu = best_mu\n",
    "        self.best_reward = self.curr_best_reward\n",
    "\n",
    "    # adaptive sigma\n",
    "    # normalization\n",
    "    stdev_reward = reward.std()\n",
    "    epsilon = self.epsilon\n",
    "    sigma = self.sigma\n",
    "    S = ((epsilon * epsilon - (sigma * sigma).reshape(1, self.num_params)) / sigma.reshape(1, self.num_params))\n",
    "    reward_avg = (reward[:self.batch_size] + reward[self.batch_size:]) / 2.0\n",
    "    rS = reward_avg - b\n",
    "    delta_sigma = (np.dot(rS, S)) / (2 * self.batch_size * stdev_reward)\n",
    "\n",
    "    # move mean to the average of the best idx means\n",
    "    self.mu += self.epsilon_full[idx].mean(axis=0)\n",
    "\n",
    "    # adjust sigma according to the adaptive sigma calculation\n",
    "    change_sigma = self.sigma_alpha * delta_sigma\n",
    "    change_sigma = np.minimum(change_sigma, self.sigma)\n",
    "    change_sigma = np.maximum(change_sigma, - 0.5 * self.sigma)\n",
    "    self.sigma += change_sigma\n",
    "    self.sigma[self.sigma > self.sigma_limit] *= self.sigma_decay\n",
    "\n",
    "  def done(self):\n",
    "    return (self.rms_stdev() < self.done_threshold)\n",
    "\n",
    "  def current_param(self):\n",
    "    return self.curr_best_mu\n",
    "  \n",
    "  def best_param(self):\n",
    "    return self.best_mu\n",
    "\n",
    "  def result(self): # return best params so far, along with historically best reward, curr reward, sigma\n",
    "    return (self.best_mu, self.best_reward, self.curr_best_reward, self.sigma)\n",
    "\n",
    "class SimpleGA:\n",
    "  '''Simple Genetic Algorithm.'''\n",
    "  def __init__(self, num_params,      # number of model parameters\n",
    "               sigma_init=0.1,        # initial standard deviation\n",
    "               sigma_decay=0.999,     # anneal standard deviation\n",
    "               sigma_limit=0.01,      # stop annealing if less than this\n",
    "               popsize=255,           # population size\n",
    "               elite_ratio=0.1,       # percentage of the elites\n",
    "               forget_best=False,     # forget the historical best elites\n",
    "               done_threshold=1e-6):  # threshold when we say we are done\n",
    "\n",
    "    self.num_params = num_params\n",
    "    self.sigma_init = sigma_init\n",
    "    self.sigma_decay = sigma_decay\n",
    "    self.sigma_limit = sigma_limit\n",
    "    self.popsize = popsize\n",
    "\n",
    "    self.elite_ratio = elite_ratio\n",
    "    self.elite_popsize = int(self.popsize * self.elite_ratio)\n",
    "\n",
    "    self.sigma = self.sigma_init\n",
    "    self.elite_params = np.zeros((self.elite_popsize, self.num_params))\n",
    "    self.elite_rewards = np.zeros(self.elite_popsize)\n",
    "    self.best_param = np.zeros(self.num_params)\n",
    "    self.best_reward = 0\n",
    "    self.first_iteration = True\n",
    "    self.forget_best = forget_best\n",
    "    self.done_threshold = done_threshold\n",
    "\n",
    "  def rms_stdev(self):\n",
    "    return self.sigma # same sigma for all parameters.\n",
    "\n",
    "  def ask(self):\n",
    "    '''returns a list of parameters'''\n",
    "    # antithetic sampling\n",
    "    self.epsilon = np.random.randn(self.popsize, self.num_params) * self.sigma\n",
    "    solutions = []\n",
    "    \n",
    "    def mate(a, b):\n",
    "      c = np.copy(a)\n",
    "      idx = np.where(np.random.rand((c.size)) > 0.5)\n",
    "      c[idx] = b[idx]\n",
    "      return c\n",
    "    \n",
    "    elite_range = range(self.elite_popsize)\n",
    "    for i in range(self.popsize):\n",
    "      idx_a = np.random.choice(elite_range)\n",
    "      idx_b = np.random.choice(elite_range)\n",
    "      child_params = mate(self.elite_params[idx_a], self.elite_params[idx_b])\n",
    "      solutions.append(child_params + self.epsilon[i])\n",
    "\n",
    "    solutions = np.array(solutions)\n",
    "    self.solutions = solutions\n",
    "\n",
    "    return solutions\n",
    "\n",
    "  def tell(self, reward_table_result):\n",
    "    # input must be a numpy float array\n",
    "    assert(len(reward_table_result) == self.popsize), \"Inconsistent reward_table size reported.\"\n",
    "    \n",
    "    if (not self.forget_best or self.first_iteration):\n",
    "      reward = reward_table_result\n",
    "      solution = self.solutions\n",
    "    else:\n",
    "      reward = np.concatenate([reward_table_result, self.elite_rewards])\n",
    "      solution = np.concatenate([self.solutions, self.elite_params])\n",
    "\n",
    "    idx = np.argsort(reward)[::-1][0:self.elite_popsize]\n",
    "\n",
    "    self.elite_rewards = reward[idx]\n",
    "    self.elite_params = solution[idx]\n",
    "\n",
    "    self.curr_best_reward = self.elite_rewards[0]\n",
    "    \n",
    "    if self.first_iteration or (self.curr_best_reward > self.best_reward):\n",
    "      self.first_iteration = False\n",
    "      self.best_reward = self.elite_rewards[0]\n",
    "      self.best_param = np.copy(self.elite_params[0])\n",
    "\n",
    "    if (self.sigma > self.sigma_limit):\n",
    "      self.sigma *= self.sigma_decay\n",
    "\n",
    "  def done(self):\n",
    "    return (self.rms_stdev() < self.done_threshold)\n",
    "\n",
    "  def current_param(self):\n",
    "    return self.elite_params[0]\n",
    "\n",
    "  def best_param(self):\n",
    "    return self.best_param\n",
    "\n",
    "  def result(self): # return best params so far, along with historically best reward, curr reward, sigma\n",
    "    return (self.best_param, self.best_reward, self.curr_best_reward, self.sigma)\n",
    "\n",
    "class OpenES:\n",
    "  ''' Basic Version of OpenAI Evolution Strategies.'''\n",
    "  def __init__(self, num_params,             # number of model parameters\n",
    "               sigma_init=0.1,               # initial standard deviation\n",
    "               sigma_decay=0.999,            # anneal standard deviation\n",
    "               sigma_limit=0.01,             # stop annealing if less than this\n",
    "               learning_rate=0.001,          # learning rate for standard deviation\n",
    "               learning_rate_decay = 0.9999, # annealing the learning rate\n",
    "               learning_rate_limit = 0.001,  # stop annealing learning rate\n",
    "               popsize=255,                  # population size\n",
    "               antithetic=False,             # whether to use antithetic sampling\n",
    "               forget_best=True):           # forget historical best\n",
    "\n",
    "    self.num_params = num_params\n",
    "    self.sigma_decay = sigma_decay\n",
    "    self.sigma = sigma_init\n",
    "    self.sigma_limit = sigma_limit\n",
    "    self.learning_rate = learning_rate\n",
    "    self.learning_rate_decay = learning_rate_decay\n",
    "    self.learning_rate_limit = learning_rate_limit\n",
    "    self.popsize = popsize\n",
    "    self.antithetic = antithetic\n",
    "    if self.antithetic:\n",
    "      assert (self.popsize & 2), \"Population size must be even\"\n",
    "      self.half_popsize = int(self.popsize / 2)\n",
    "\n",
    "    self.reward = np.zeros(self.popsize)\n",
    "    self.mu = np.zeros(self.num_params)\n",
    "    self.best_mu = np.zeros(self.num_params)\n",
    "    self.best_reward = 0\n",
    "    self.first_interation = True\n",
    "    self.forget_best = forget_best\n",
    "\n",
    "  def rms_stdev(self):\n",
    "    sigma = self.sigma\n",
    "    return np.mean(np.sqrt(sigma*sigma))\n",
    "\n",
    "  def ask(self):\n",
    "    '''returns a list of parameters'''\n",
    "    # antithetic sampling\n",
    "    if self.antithetic:\n",
    "      self.epsilon_half = np.random.randn(self.half_popsize, self.num_params)\n",
    "      self.epsilon = np.concatenate([self.epsilon_half, - self.epsilon_half])\n",
    "    else:\n",
    "      self.epsilon = np.random.randn(self.popsize, self.num_params)\n",
    "\n",
    "    self.solutions = self.mu.reshape(1, self.num_params) + self.epsilon * self.sigma\n",
    "\n",
    "    return self.solutions\n",
    "\n",
    "  def tell(self, reward):\n",
    "    # input must be a numpy float array\n",
    "    assert(len(reward) == self.popsize), \"Inconsistent reward_table size reported.\"\n",
    "\n",
    "    idx = np.argsort(reward)[::-1]\n",
    "\n",
    "    best_reward = reward[idx[0]]\n",
    "    best_mu = self.solutions[idx[0]]\n",
    "\n",
    "    self.curr_best_reward = best_reward\n",
    "    self.curr_best_mu = best_mu\n",
    "\n",
    "    if self.first_interation:\n",
    "      self.first_interation = False\n",
    "      self.best_reward = self.curr_best_reward\n",
    "      self.best_mu = best_mu\n",
    "    else:\n",
    "      if self.forget_best or (self.curr_best_reward > self.best_reward):\n",
    "        self.best_mu = best_mu\n",
    "        self.best_reward = self.curr_best_reward\n",
    "\n",
    "    # main bit:\n",
    "    # standardize the rewards to have a gaussian distribution\n",
    "    normalized_reward = (reward - np.mean(reward)) / np.std(reward)\n",
    "    self.mu += self.learning_rate/(self.popsize*self.sigma)*np.dot(self.epsilon.T, normalized_reward)\n",
    "\n",
    "    # adjust sigma according to the adaptive sigma calculation\n",
    "    if (self.sigma > self.sigma_limit):\n",
    "      self.sigma *= self.sigma_decay\n",
    "\n",
    "    if (self.learning_rate > self.learning_rate_limit):\n",
    "      self.learning_rate *= self.learning_rate_decay\n",
    "\n",
    "  def done(self):\n",
    "    return False\n",
    "\n",
    "  def current_param(self):\n",
    "    return self.curr_best_mu\n",
    "\n",
    "  def best_param(self):\n",
    "    return self.best_mu\n",
    "\n",
    "  def result(self): # return best params so far, along with historically best reward, curr reward, sigma\n",
    "    return (self.best_mu, self.best_reward, self.curr_best_reward, self.sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Args = namedtuple('Args', ['batch_size', 'test_batch_size', 'epochs', 'lr', 'cuda', 'seed', 'log_interval'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args(batch_size=1000, test_batch_size=1000, epochs=30, lr=0.001, cuda=False, seed=0, log_interval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(args.seed)\n",
    "if args.cuda:\n",
    "  torch.cuda.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d288b72bc5d4f54bcbc68094ba7b13b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d4203e09a5247c1a3c6a807615aae5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c034dff1cbf64383ba7e40431670be76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9675812dbf304f40a8dc22cca79806fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw\n",
      "\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages/torchvision/datasets/mnist.py:502: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:143.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  datasets.MNIST('MNIST_data', train=True, download=True, transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])),\n",
    "  batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "valid_loader = train_loader\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  datasets.MNIST('MNIST_data', train=False, transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])),\n",
    "  batch_size=args.batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net, self).__init__()\n",
    "    self.num_filter1 = 8\n",
    "    self.num_filter2 = 16\n",
    "    self.num_padding = 2\n",
    "    # input is 28x28\n",
    "    # padding=2 for same padding\n",
    "    self.conv1 = nn.Conv2d(1, self.num_filter1, 5, padding=self.num_padding)\n",
    "    # feature map size is 14*14 by pooling\n",
    "    # padding=2 for same padding\n",
    "    self.conv2 = nn.Conv2d(self.num_filter1, self.num_filter2, 5, padding=self.num_padding)\n",
    "    # feature map size is 7*7 by pooling\n",
    "    self.fc = nn.Linear(self.num_filter2*7*7, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "    x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "    x = x.view(-1, self.num_filter2*7*7)   # reshape Variable\n",
    "    x = self.fc(x)\n",
    "    return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NPOPULATION = 101\n",
    "weight_decay_coef = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "models = []\n",
    "for i in range(NPOPULATION):\n",
    "  model = Net()\n",
    "  if args.cuda:\n",
    "    model.cuda()\n",
    "  model.eval()\n",
    "  models.append(model)\n",
    "'''\n",
    "\n",
    "model = Net()\n",
    "if args.cuda:\n",
    "  model.cuda()\n",
    "\n",
    "orig_model = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11274\n"
     ]
    }
   ],
   "source": [
    "# get init params\n",
    "orig_params = []\n",
    "model_shapes = []\n",
    "for param in orig_model.parameters():\n",
    "  p = param.data.cpu().numpy()\n",
    "  model_shapes.append(p.shape)\n",
    "  orig_params.append(p.flatten())\n",
    "orig_params_flat = np.concatenate(orig_params)\n",
    "NPARAMS = len(orig_params_flat)\n",
    "print(NPARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_model(flat_param, model, model_shapes):\n",
    "  idx = 0\n",
    "  i = 0\n",
    "  for param in model.parameters():\n",
    "    delta = np.product(model_shapes[i])\n",
    "    block = flat_param[idx:idx+delta]\n",
    "    block = np.reshape(block, model_shapes[i])\n",
    "    i += 1\n",
    "    idx += delta\n",
    "    block_data = torch.from_numpy(block).float()\n",
    "    if args.cuda:\n",
    "      block_data = block_data.cuda()\n",
    "    param.data = block_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader, print_mode=True, return_loss=False):\n",
    "  model.eval()\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  for data, target in test_loader:\n",
    "    if args.cuda:\n",
    "      data, target = data.cuda(), target.cuda()\n",
    "    data, target = Variable(data, volatile=True), Variable(target)\n",
    "    output = model(data)\n",
    "    test_loss += F.nll_loss(output, target, size_average=False).item() # sum up batch loss\n",
    "    pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "    correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "  test_loss /= len(test_loader.dataset)\n",
    "  acc = correct / len(test_loader.dataset)\n",
    "  \n",
    "  if print_mode:\n",
    "    print('\\nAverage loss: {:.4f}, Accuracy: {}/{} ({:.4f}%)\\n'.format(\n",
    "      test_loss, correct, len(test_loader.dataset),\n",
    "      100. * acc))\n",
    "  \n",
    "  if return_loss:\n",
    "    return test_loss\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50_w,101)-aCMA-ES (mu_w=27.2,w_1=8%) in dimension 11274 (seed=910463, Sun Oct 31 20:59:14 2021)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "es = SimpleES(NPARAMS,\n",
    "              popsize=NPOPULATION,\n",
    "              sigma_init=0.01,\n",
    "              sigma_decay=0.999,\n",
    "              sigma_alpha=0.2,\n",
    "              sigma_limit=0.001,\n",
    "              elite_ratio=0.1,\n",
    "              average_baseline=False,\n",
    "              forget_best=True\n",
    "             )\n",
    "\"\"\"\n",
    "es = CMAES(NPARAMS, sigma_init=0.01, popsize=NPOPULATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker(procnum, model, solution, data, target, send_end):\n",
    "  update_model(solution, model, model_shapes)\n",
    "  output = model(data)\n",
    "  loss = F.nll_loss(output, target)\n",
    "  reward = - loss.data[0]\n",
    "  send_end.send(reward)\n",
    "\n",
    "def batch_simulation(model_list, solutions, data, target, process_count):\n",
    "  jobs = []\n",
    "  pipe_list = []\n",
    "\n",
    "  for i in range(process_count):\n",
    "    recv_end, send_end = mp.Pipe(False)\n",
    "    p = mp.Process(target=worker, args=(i, model_list[i], solutions[i], data, target, send_end))\n",
    "    jobs.append(p)\n",
    "    pipe_list.append(recv_end)\n",
    "\n",
    "  for p in jobs:\n",
    "    p.start()\n",
    "\n",
    "  for p in jobs:\n",
    "    p.join()\n",
    "\n",
    "  result_list = [x.recv() for x in pipe_list]\n",
    "  return np.array(result_list)\n",
    "\n",
    "\n",
    "def batch_simulation_sequential(model_list, solutions, data, target, process_count):\n",
    "  result_list = []\n",
    "  for i in range(process_count):\n",
    "    update_model(solutions[i], model_list[i], model_shapes)\n",
    "    output = model_list[i](data)\n",
    "    loss = F.nll_loss(output, target)\n",
    "    reward = - loss.item()\n",
    "    result_list.append(reward)\n",
    "  return np.array(result_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-aa6b7b8bbee1>:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0 -2.301851749420166 7.887820135329692e-06 0.009976341014506163\n",
      "1 5 -2.300994634628296 -4.2091417018916056e-05 0.00986665618522879\n",
      "1 10 -2.300433874130249 0.000113597395842203 0.009767401183264126\n",
      "1 15 -2.297788619995117 0.0001877900003550239 0.00967553391952183\n",
      "1 20 -2.298326253890991 0.00018249261271607091 0.009589924758448155\n",
      "1 25 -2.2891440391540527 0.0006169734737803527 0.009509658254634953\n",
      "1 30 -2.2805235385894775 0.00028616857454489495 0.009434264282554559\n",
      "1 35 -2.2605648040771484 0.0005454265362508403 0.009363461170778482\n",
      "1 40 -2.235072374343872 0.0007473862052016282 0.00929699098612747\n",
      "1 45 -2.208850622177124 0.000833086551606858 0.009234320409214382\n",
      "1 50 -2.1692183017730713 0.0008720435258368781 0.009175540193998598\n",
      "1 55 -2.1218955516815186 0.0010666503266339989 0.009120210183854126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-e1ba295ddbc0>:8: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\n",
      "/usr/local/Cellar/jupyterlab/3.0.14/libexec/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_acc tensor(60.8167)\n",
      "best valid_acc tensor(60.8167)\n",
      "2 0 -2.0604007244110107 0.001378682315845737 0.009067907034899106\n",
      "2 5 -2.001070022583008 0.001426392386765988 0.009018666528893438\n",
      "2 10 -1.9433016777038574 0.0016104792153792456 0.008972269037950368\n",
      "2 15 -1.8907808065414429 0.0015181469596615184 0.008928164062802491\n",
      "2 20 -1.8302048444747925 0.0015651836975691946 0.008886555551246136\n",
      "2 25 -1.721839189529419 0.0018065291387721664 0.008847556916952593\n",
      "2 30 -1.6369894742965698 0.0018039886209407579 0.008811146291199964\n",
      "2 35 -1.5363309383392334 0.001919224873571759 0.008777053398816455\n",
      "2 40 -1.4754207134246826 0.0019466518381656185 0.008745240303027693\n",
      "2 45 -1.4105268716812134 0.0022171922538297252 0.008715363748858212\n",
      "2 50 -1.2977548837661743 0.0022948319164751135 0.008687375665160705\n",
      "2 55 -1.2342201471328735 0.0023716393980282875 0.008661518118758156\n",
      "valid_acc tensor(74.0217)\n",
      "best valid_acc tensor(74.0217)\n",
      "3 0 -1.1803454160690308 0.002392972774804592 0.008637358336944925\n",
      "3 5 -1.087454080581665 0.0025574759962601417 0.008614737967261038\n",
      "3 10 -1.0487215518951416 0.0024878010752964496 0.008593634286755497\n",
      "3 15 -1.0091475248336792 0.002408520119031449 0.008573848851198471\n",
      "3 20 -0.9810735583305359 0.0023215904585517323 0.008555354601570777\n",
      "3 25 -0.9245542883872986 0.0023215904585517323 0.008538128501977786\n",
      "3 30 -0.9165605902671814 0.002438324067651605 0.00852196124177331\n",
      "3 35 -0.8833434581756592 0.0025436181880096245 0.008506846947736452\n",
      "3 40 -0.798940122127533 0.0026573112460013377 0.008492777089959807\n",
      "3 45 -0.760073721408844 0.0025773455092304868 0.008479592333797715\n",
      "3 50 -0.7450547814369202 0.002809689231595377 0.008467175605141403\n",
      "3 55 -0.7704917788505554 0.00266336417715887 0.0084553518010506\n",
      "valid_acc tensor(81.1350)\n",
      "best valid_acc tensor(81.1350)\n",
      "4 0 -0.709647536277771 0.002740275822690084 0.008444273947407176\n",
      "4 5 -0.6910141110420227 0.00281764089029797 0.008434040273060828\n",
      "4 10 -0.7009917497634888 0.00281764089029797 0.008424559557432352\n",
      "4 15 -0.6701743602752686 0.0027866303148323507 0.008415822299417803\n",
      "4 20 -0.6593836545944214 0.0027866303148323507 0.008407504770304882\n",
      "4 25 -0.6729257106781006 0.002700042199464626 0.008399727921195291\n",
      "4 30 -0.6501632332801819 0.0027253875454545645 0.008392731601221231\n",
      "4 35 -0.6314758658409119 0.0027253875454545645 0.008386460539059065\n",
      "4 40 -0.6476203203201294 0.002473164936531178 0.0083808390709694\n",
      "4 45 -0.612697958946228 0.002765171220328505 0.008375622254816683\n",
      "4 50 -0.5656188726425171 0.0026922037976167446 0.008370881642915752\n",
      "4 55 -0.6317071318626404 0.0026922037976167446 0.008366667492434745\n",
      "valid_acc tensor(84.3717)\n",
      "best valid_acc tensor(84.3717)\n",
      "5 0 -0.5837668180465698 0.0026922037976167446 0.008362827408343931\n",
      "5 5 -0.5886051654815674 0.002828086221999638 0.008359423723307472\n",
      "5 10 -0.5371261835098267 0.002773223983677546 0.008356379232854066\n",
      "5 15 -0.6039218902587891 0.002773223983677546 0.008353681859059962\n",
      "5 20 -0.5535893440246582 0.0030225703119136976 0.008351215498209929\n",
      "5 25 -0.5406791567802429 0.002991227404204972 0.00834915121948876\n",
      "5 30 -0.5077367424964905 0.003077434698564803 0.008347750472433748\n",
      "5 35 -0.5803686380386353 0.003077434698564803 0.008346499395511608\n",
      "5 40 -0.5097306370735168 0.003009656642556102 0.00834548358006709\n",
      "5 45 -0.5101194381713867 0.003009656642556102 0.008344777904588898\n",
      "5 50 -0.5296384692192078 0.003009656642556102 0.008344190895693427\n",
      "5 55 -0.5283142328262329 0.003009656642556102 0.008343676530525642\n",
      "valid_acc tensor(85.7817)\n",
      "best valid_acc tensor(85.7817)\n",
      "6 0 -0.49813705682754517 0.003009656642556102 0.008343110614843025\n",
      "6 5 -0.5124169588088989 0.00313874975963959 0.00834266849348812\n",
      "6 10 -0.4927670359611511 0.00313874975963959 0.008342578560143627\n",
      "6 15 -0.48318424820899963 0.00313874975963959 0.008342576521308563\n",
      "6 20 -0.5396780371665955 0.00313874975963959 0.008342592217051855\n",
      "6 25 -0.5233531594276428 0.0031850006352038803 0.008342681540913858\n",
      "6 30 -0.5271293520927429 0.003183820446506114 0.008342921873988777\n",
      "6 35 -0.47346562147140503 0.003183820446506114 0.008343097121433312\n",
      "6 40 -0.47238245606422424 0.0032475723022595765 0.008343313107678555\n",
      "6 45 -0.5629846453666687 0.0032475723022595765 0.0083437462293764\n",
      "6 50 -0.4431324303150177 0.0032475723022595765 0.008344289098588581\n",
      "6 55 -0.5038515329360962 0.0032475723022595765 0.00834468078152358\n",
      "valid_acc tensor(86.4150)\n",
      "best valid_acc tensor(86.4150)\n",
      "7 0 -0.4254431128501892 0.0033028641141739836 0.008345107247858315\n",
      "7 5 -0.4794922471046448 0.0033028641141739836 0.008345687282499126\n",
      "7 10 -0.47300076484680176 0.0033028641141739836 0.008346323500965813\n",
      "7 15 -0.4278266429901123 0.0033028641141739836 0.008347194466764645\n",
      "7 20 -0.4497680366039276 0.0032428141295185076 0.008348284126609392\n",
      "7 25 -0.4500175714492798 0.0032428141295185076 0.008349457378982236\n",
      "7 30 -0.4648478329181671 0.0032428141295185076 0.008350768841621732\n",
      "7 35 -0.4933569133281708 0.0032428141295185076 0.008352086643277535\n",
      "7 40 -0.3916475772857666 0.00341653686322852 0.008353517922604607\n",
      "7 45 -0.4549844264984131 0.00341653686322852 0.008355045471274337\n",
      "7 50 -0.4321662187576294 0.00341653686322852 0.008356551528809257\n",
      "7 55 -0.427546888589859 0.00341653686322852 0.008358252899920031\n",
      "valid_acc tensor(87.3183)\n",
      "best valid_acc tensor(87.3183)\n",
      "8 0 -0.4359777569770813 0.00341653686322852 0.008359885719057762\n",
      "8 5 -0.4157271981239319 0.00341653686322852 0.008361816924145005\n",
      "8 10 -0.43259063363075256 0.00341653686322852 0.008363841563283141\n",
      "8 15 -0.43921810388565063 0.00341653686322852 0.008365756108262757\n",
      "8 20 -0.4428896903991699 0.003240475789846584 0.008367718689972862\n",
      "8 25 -0.42309844493865967 0.003240475789846584 0.008369881357641626\n",
      "8 30 -0.4119894206523895 0.003240475789846584 0.00837211600670061\n",
      "8 35 -0.45007479190826416 0.003240475789846584 0.008374359611226295\n",
      "8 40 -0.4255215525627136 0.003240475789846584 0.008376643814422586\n",
      "8 45 -0.40519213676452637 0.003240475789846584 0.008379026132734758\n",
      "8 50 -0.46916463971138 0.003240475789846584 0.008381490108411428\n",
      "8 55 -0.45201075077056885 0.003240475789846584 0.00838393485944395\n",
      "valid_acc tensor(88.0117)\n",
      "best valid_acc tensor(88.0117)\n",
      "9 0 -0.37524735927581787 0.003240475789846584 0.008386277462693182\n",
      "9 5 -0.45281505584716797 0.003240475789846584 0.0083885850994012\n",
      "9 10 -0.4657924473285675 0.003240475789846584 0.00839094379243306\n",
      "9 15 -0.4074309170246124 0.0036086655985162744 0.008393429752423135\n",
      "9 20 -0.41362059116363525 0.0036086655985162744 0.008395831382763822\n",
      "9 25 -0.4099731743335724 0.0034528524120659263 0.00839819023696909\n",
      "9 30 -0.4288434684276581 0.0035975229730059195 0.008400433430418458\n",
      "9 35 -0.43478959798812866 0.0035975229730059195 0.008402943788756227\n",
      "9 40 -0.4401208758354187 0.0035975229730059195 0.008405303616386917\n",
      "9 45 -0.44135504961013794 0.0035975229730059195 0.008407679928922253\n",
      "9 50 -0.3693084418773651 0.0035975229730059195 0.008410004162342388\n",
      "9 55 -0.41698893904685974 0.0035975229730059195 0.008412393569392124\n",
      "valid_acc tensor(88.5717)\n",
      "best valid_acc tensor(88.5717)\n",
      "10 0 -0.3576796352863312 0.003302844901455218 0.008414691728365304\n",
      "10 5 -0.40303751826286316 0.003302844901455218 0.008417105963389298\n",
      "10 10 -0.4772595167160034 0.003302844901455218 0.008419590602829994\n",
      "10 15 -0.3730681240558624 0.003302844901455218 0.008422080939652188\n",
      "10 20 -0.3408701717853546 0.0034624882627295735 0.008424524465288467\n",
      "10 25 -0.3888629674911499 0.0034624882627295735 0.008426898063411785\n",
      "10 30 -0.3578488826751709 0.0034624882627295735 0.00842917869632846\n",
      "10 35 -0.39541855454444885 0.0034624882627295735 0.008431373354904109\n",
      "10 40 -0.3950199782848358 0.0034624882627295735 0.008433321923695959\n",
      "10 45 -0.38411882519721985 0.0034624882627295735 0.008435213925904139\n",
      "10 50 -0.3936064839363098 0.0034624882627295735 0.008437113537549135\n",
      "10 55 -0.40372830629348755 0.0034624882627295735 0.008438991591130186\n",
      "valid_acc tensor(88.7317)\n",
      "best valid_acc tensor(88.7317)\n",
      "11 0 -0.460553914308548 0.0034624882627295735 0.008440633749397708\n",
      "11 5 -0.386709600687027 0.0034624882627295735 0.008442270902848674\n",
      "11 10 -0.4409990906715393 0.0034624882627295735 0.008443602247600573\n",
      "11 15 -0.3539845645427704 0.0033305851081646804 0.008444728327022743\n",
      "11 20 -0.35663318634033203 0.0033305851081646804 0.008445692304903447\n",
      "11 25 -0.39070022106170654 0.003441508023999272 0.008446518705019572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 30 -0.412170946598053 0.003441508023999272 0.008447562338976363\n",
      "11 35 -0.3725285828113556 0.003441508023999272 0.00844874628179823\n",
      "11 40 -0.389311820268631 0.003441508023999272 0.00845001781308479\n",
      "11 45 -0.3991018235683441 0.003441508023999272 0.008451520820173754\n",
      "11 50 -0.394558846950531 0.003441508023999272 0.008453361138867032\n",
      "11 55 -0.3831705152988434 0.003441508023999272 0.008455102984127535\n",
      "valid_acc tensor(89.2450)\n",
      "best valid_acc tensor(89.2450)\n",
      "12 0 -0.39547213912010193 0.003441508023999272 0.008456920366247402\n",
      "12 5 -0.36085301637649536 0.003441508023999272 0.008458783316775931\n",
      "12 10 -0.359577476978302 0.003441508023999272 0.00846061623488515\n",
      "12 15 -0.3564721941947937 0.003441508023999272 0.008462385413460507\n",
      "12 20 -0.34636780619621277 0.003414725385114279 0.008464065265075926\n",
      "12 25 -0.41664424538612366 0.003414725385114279 0.008465919282318676\n",
      "12 30 -0.3859668970108032 0.003414725385114279 0.00846791281097583\n",
      "12 35 -0.36103981733322144 0.003414725385114279 0.008469881416193762\n",
      "12 40 -0.39022350311279297 0.003414725385114279 0.008471500046929287\n",
      "12 45 -0.4192275404930115 0.003414725385114279 0.008473043868755142\n",
      "12 50 -0.3977063000202179 0.003414725385114279 0.008474606467668244\n",
      "12 55 -0.34440213441848755 0.003414725385114279 0.008476045071556984\n",
      "valid_acc tensor(89.5167)\n",
      "best valid_acc tensor(89.5167)\n",
      "13 0 -0.35955554246902466 0.003414725385114279 0.008477557566018814\n",
      "13 5 -0.30685675144195557 0.003414725385114279 0.008479173150773562\n",
      "13 10 -0.3370175361633301 0.003414725385114279 0.008480863019412763\n",
      "13 15 -0.3449075222015381 0.003414725385114279 0.008482370997650514\n",
      "13 20 -0.38132229447364807 0.003414725385114279 0.008483678864314084\n",
      "13 25 -0.35056883096694946 0.003414725385114279 0.008484834718970404\n",
      "13 30 -0.370988667011261 0.003414725385114279 0.008486044176659083\n",
      "13 35 -0.3494475483894348 0.003414725385114279 0.008487206430051906\n",
      "13 40 -0.2994428277015686 0.003414725385114279 0.008488521451737289\n",
      "13 45 -0.37256568670272827 0.003414725385114279 0.008489842171947827\n",
      "13 50 -0.39717230200767517 0.003414725385114279 0.008491005769744844\n",
      "13 55 -0.284991055727005 0.0032288150258795033 0.00849206393752328\n",
      "valid_acc tensor(90.0050)\n",
      "best valid_acc tensor(90.0050)\n",
      "14 0 -0.36809560656547546 0.0032288150258795033 0.008493022637292517\n",
      "14 5 -0.32823607325553894 0.0032288150258795033 0.008494099730914452\n",
      "14 10 -0.3148435354232788 0.0032288150258795033 0.00849518447504778\n",
      "14 15 -0.3800990581512451 0.0032288150258795033 0.008496040560168233\n",
      "14 20 -0.3327358067035675 0.0032288150258795033 0.008496952836723174\n",
      "14 25 -0.3773946762084961 0.0032288150258795033 0.00849794336660642\n",
      "14 30 -0.34438636898994446 0.0032288150258795033 0.00849885562994276\n",
      "14 35 -0.37204164266586304 0.0032288150258795033 0.008499881313494032\n",
      "14 40 -0.32982146739959717 0.0032288150258795033 0.00850073844012935\n",
      "14 45 -0.2835228443145752 0.003238751465728036 0.008501476334482809\n",
      "14 50 -0.30283284187316895 0.003238751465728036 0.008501961429252447\n",
      "14 55 -0.3584185242652893 0.003254526988904727 0.00850261421326758\n",
      "valid_acc tensor(90.2650)\n",
      "best valid_acc tensor(90.2650)\n",
      "15 0 -0.3351009786128998 0.003254526988904727 0.008503293489713105\n",
      "15 5 -0.3128982484340668 0.003254526988904727 0.008503907830284268\n",
      "15 10 -0.32060477137565613 0.003254526988904727 0.0085046461342079\n",
      "15 15 -0.36772239208221436 0.003254526988904727 0.008505552516966781\n",
      "15 20 -0.3051733672618866 0.003254526988904727 0.008506219788590782\n",
      "15 25 -0.3397499918937683 0.003254526988904727 0.008507033511808048\n",
      "15 30 -0.3333272337913513 0.003254526988904727 0.008507964735403427\n",
      "15 35 -0.32656410336494446 0.003254526988904727 0.008509026245856205\n",
      "15 40 -0.3231543302536011 0.003254526988904727 0.008510051837892682\n",
      "15 45 -0.3742772340774536 0.003254526988904727 0.008511089048549242\n",
      "15 50 -0.34411948919296265 0.0034195176723072034 0.008512104122657845\n",
      "15 55 -0.29339903593063354 0.0034195176723072034 0.00851303453466571\n",
      "valid_acc tensor(90.7117)\n",
      "best valid_acc tensor(90.7117)\n",
      "16 0 -0.3130785822868347 0.0034195176723072034 0.00851398969685499\n",
      "16 5 -0.3300494849681854 0.0034195176723072034 0.008515003100666465\n",
      "16 10 -0.33440348505973816 0.0034195176723072034 0.008516018570324017\n",
      "16 15 -0.29766029119491577 0.0034195176723072034 0.008516930751759758\n",
      "16 20 -0.29240792989730835 0.0034195176723072034 0.008517867150845832\n",
      "16 25 -0.277971476316452 0.0034195176723072034 0.008518937860632833\n",
      "16 30 -0.3353895843029022 0.0034195176723072034 0.008519903462315627\n",
      "16 35 -0.3396580219268799 0.0034195176723072034 0.008520680399300906\n",
      "16 40 -0.30911582708358765 0.0034195176723072034 0.008521736612464763\n",
      "16 45 -0.2925255000591278 0.0034195176723072034 0.008522917926512056\n",
      "16 50 -0.2990834414958954 0.0034195176723072034 0.008524051588693845\n",
      "16 55 -0.33443179726600647 0.0034195176723072034 0.008525131101725413\n",
      "valid_acc tensor(90.9933)\n",
      "best valid_acc tensor(90.9933)\n",
      "17 0 -0.3001945912837982 0.0031316049876618183 0.008525901301325923\n",
      "17 5 -0.2911829948425293 0.0031316049876618183 0.008526620402249222\n",
      "17 10 -0.2976606488227844 0.0031316049876618183 0.00852735805456464\n",
      "17 15 -0.3155514895915985 0.0031316049876618183 0.008528180832192646\n",
      "17 20 -0.32634931802749634 0.0031316049876618183 0.008529241964323574\n",
      "17 25 -0.3079073429107666 0.0031316049876618183 0.008530369551632977\n",
      "17 30 -0.31091392040252686 0.0031316049876618183 0.008531321301468758\n",
      "17 35 -0.3207884132862091 0.0031316049876618183 0.008532481100622973\n",
      "17 40 -0.28937289118766785 0.0031316049876618183 0.008533892041046202\n",
      "17 45 -0.2922925353050232 0.0031316049876618183 0.00853527350885888\n",
      "17 50 -0.30670636892318726 0.0031316049876618183 0.00853676517247306\n",
      "17 55 -0.30253860354423523 0.0031316049876618183 0.008538181798792807\n",
      "valid_acc tensor(91.1667)\n",
      "best valid_acc tensor(91.1667)\n",
      "18 0 -0.2957189977169037 0.0031316049876618183 0.008539594353856511\n",
      "18 5 -0.3398579955101013 0.0031316049876618183 0.008541032854241208\n",
      "18 10 -0.308475136756897 0.0031316049876618183 0.00854237590591457\n",
      "18 15 -0.324856698513031 0.0031316049876618183 0.00854354537729989\n",
      "18 20 -0.28435295820236206 0.0031316049876618183 0.00854468723419121\n",
      "18 25 -0.2905486226081848 0.0031316049876618183 0.008546002714881006\n",
      "18 30 -0.2465890645980835 0.003144160592543514 0.008547488758100246\n",
      "18 35 -0.31795090436935425 0.0030563613678165325 0.008549068259905368\n",
      "18 40 -0.2720259726047516 0.0030563613678165325 0.00855084799892016\n",
      "18 45 -0.2766314446926117 0.0030563613678165325 0.008552395754345353\n",
      "18 50 -0.313662052154541 0.0030563613678165325 0.008554044324697776\n",
      "18 55 -0.2895057499408722 0.0030563613678165325 0.008555652401699447\n",
      "valid_acc tensor(91.5450)\n",
      "best valid_acc tensor(91.5450)\n",
      "19 0 -0.27965760231018066 0.0030563613678165325 0.008557433547665074\n",
      "19 5 -0.2596515715122223 0.0030563613678165325 0.008559269797680728\n",
      "19 10 -0.32599496841430664 0.0030563613678165325 0.008560897808188405\n",
      "19 15 -0.2814866602420807 0.0030563613678165325 0.008562736920972652\n",
      "19 20 -0.3091306984424591 0.0029446875922724053 0.008564491893872645\n",
      "19 25 -0.28301650285720825 0.0029446875922724053 0.0085662199123734\n",
      "19 30 -0.3503342270851135 0.0029446875922724053 0.008568039882334266\n",
      "19 35 -0.2858526110649109 0.0029446875922724053 0.008569712493602217\n",
      "19 40 -0.2981858253479004 0.0029446875922724053 0.008571400727161163\n",
      "19 45 -0.33521145582199097 0.0029446875922724053 0.008573216876761628\n",
      "19 50 -0.28704729676246643 0.0029729033826858247 0.008575168497634343\n",
      "19 55 -0.25625941157341003 0.0029729033826858247 0.008576972536554024\n",
      "valid_acc tensor(91.8767)\n",
      "best valid_acc tensor(91.8767)\n",
      "20 0 -0.2980877161026001 0.0029729033826858247 0.00857877915060473\n",
      "20 5 -0.29827848076820374 0.0029729033826858247 0.008580342887658838\n",
      "20 10 -0.2524265944957733 0.0029729033826858247 0.008582084698986397\n",
      "20 15 -0.23902617394924164 0.0029729033826858247 0.008583943275376647\n",
      "20 20 -0.2853713631629944 0.0029729033826858247 0.00858575997360272\n",
      "20 25 -0.2709759473800659 0.0029729033826858247 0.008587395348920605\n",
      "20 30 -0.2998161017894745 0.0029729033826858247 0.008588772328261255\n",
      "20 35 -0.26853838562965393 0.0029729033826858247 0.008590336954082576\n",
      "20 40 -0.251603901386261 0.0029729033826858247 0.008591891446347746\n",
      "20 45 -0.27832186222076416 0.0030571026682520886 0.00859327715825202\n",
      "20 50 -0.2710503935813904 0.0030571026682520886 0.008594826954170881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 55 -0.28838902711868286 0.0030571026682520886 0.00859636523219964\n",
      "valid_acc tensor(92.0183)\n",
      "best valid_acc tensor(92.0183)\n",
      "21 0 -0.25535303354263306 0.0030571026682520886 0.0085979543844475\n",
      "21 5 -0.2873676121234894 0.0030571026682520886 0.008599466151278174\n",
      "21 10 -0.31814560294151306 0.0030571026682520886 0.008600798964904944\n",
      "21 15 -0.25940650701522827 0.0030571026682520886 0.008602036646116442\n",
      "21 20 -0.29940661787986755 0.0030571026682520886 0.008602953160145711\n",
      "21 25 -0.3141910433769226 0.0030571026682520886 0.008603605133978802\n",
      "21 30 -0.270010769367218 0.0030571026682520886 0.008604163433468592\n",
      "21 35 -0.27304527163505554 0.0030571026682520886 0.008604599333938385\n",
      "21 40 -0.2887376844882965 0.0030571026682520886 0.008604945834063753\n",
      "21 45 -0.2523435950279236 0.0030571026682520886 0.008605059823497806\n",
      "21 50 -0.25786468386650085 0.0030571026682520886 0.00860518184954687\n",
      "21 55 -0.29084908962249756 0.0030571026682520886 0.00860531245557926\n",
      "valid_acc tensor(92.1483)\n",
      "best valid_acc tensor(92.1483)\n",
      "22 0 -0.26043933629989624 0.0030571026682520886 0.008605479222387313\n",
      "22 5 -0.30448222160339355 0.0030571026682520886 0.008605682246272608\n",
      "22 10 -0.2739007771015167 0.0030571026682520886 0.00860598301453937\n",
      "22 15 -0.27306729555130005 0.0030571026682520886 0.00860648636550562\n",
      "22 20 -0.2917894124984741 0.0030571026682520886 0.0086069153337777\n",
      "22 25 -0.2836226224899292 0.0030571026682520886 0.008607294277213382\n",
      "22 30 -0.22088702023029327 0.0030571026682520886 0.008607677118574467\n",
      "22 35 -0.29189929366111755 0.0030571026682520886 0.0086078793927119\n",
      "22 40 -0.2956329882144928 0.0030571026682520886 0.00860811195326435\n",
      "22 45 -0.27140796184539795 0.0030571026682520886 0.008608507191159135\n",
      "22 50 -0.20955286920070648 0.0030295594718942353 0.008609046429151909\n",
      "22 55 -0.2934305667877197 0.0030295594718942353 0.00860934736947522\n",
      "valid_acc tensor(92.5700)\n",
      "best valid_acc tensor(92.5700)\n",
      "23 0 -0.2670385241508484 0.0030295594718942353 0.008609677933984759\n",
      "23 5 -0.26095157861709595 0.0030295594718942353 0.00861004453817934\n",
      "23 10 -0.24227255582809448 0.0030295594718942353 0.008610503955715453\n",
      "23 15 -0.23837783932685852 0.0030295594718942353 0.0086109345199008\n",
      "23 20 -0.27619311213493347 0.0030295594718942353 0.00861117750335917\n",
      "23 25 -0.2696847915649414 0.0030295594718942353 0.008611486899823849\n",
      "23 30 -0.25740721821784973 0.0030295594718942353 0.008611874415848408\n",
      "23 35 -0.2540704309940338 0.0030295594718942353 0.00861214302678383\n",
      "23 40 -0.25886303186416626 0.0030295594718942353 0.008612428868093372\n",
      "23 45 -0.23804867267608643 0.0030295594718942353 0.008612580341442785\n",
      "23 50 -0.2162453830242157 0.0030295594718942353 0.00861251945273848\n",
      "23 55 -0.22296062111854553 0.0030295594718942353 0.008612500138849273\n",
      "valid_acc tensor(92.7600)\n",
      "best valid_acc tensor(92.7600)\n",
      "24 0 -0.2711012661457062 0.0030295594718942353 0.008612525632359765\n",
      "24 5 -0.24589301645755768 0.0030295594718942353 0.008612554367055823\n",
      "24 10 -0.23431028425693512 0.0029440904659182223 0.008612675059590222\n",
      "24 15 -0.242101788520813 0.0029440904659182223 0.008612764497115264\n",
      "24 20 -0.2232026308774948 0.0029440904659182223 0.008612911932438279\n",
      "24 25 -0.17469754815101624 0.0030355523194386374 0.008613193864065463\n",
      "24 30 -0.2421492487192154 0.0030355523194386374 0.008613529132385563\n",
      "24 35 -0.2505989670753479 0.0030355523194386374 0.008613684523271114\n",
      "24 40 -0.2585115432739258 0.0030355523194386374 0.008613644748394586\n",
      "24 45 -0.263766884803772 0.0030355523194386374 0.00861385773933902\n",
      "24 50 -0.23519648611545563 0.0030355523194386374 0.00861399300726382\n",
      "24 55 -0.24249909818172455 0.0030355523194386374 0.008614110962564717\n",
      "valid_acc tensor(92.8917)\n",
      "best valid_acc tensor(92.8917)\n",
      "25 0 -0.21861425042152405 0.0030355523194386374 0.008614364557315934\n",
      "25 5 -0.2349911630153656 0.0030355523194386374 0.008614623718470953\n",
      "25 10 -0.26717835664749146 0.0030355523194386374 0.008614674830190945\n",
      "25 15 -0.2587587833404541 0.0030355523194386374 0.008614905900547464\n",
      "25 20 -0.22512052953243256 0.0030355523194386374 0.008615434377763204\n",
      "25 25 -0.2352071851491928 0.0030355523194386374 0.008615923281799342\n",
      "25 30 -0.19809263944625854 0.0030355523194386374 0.008616523578682377\n",
      "25 35 -0.2679518759250641 0.0030355523194386374 0.008617220630128349\n",
      "25 40 -0.22456510365009308 0.0030355523194386374 0.008617812099421229\n",
      "25 45 -0.2560010850429535 0.0030355523194386374 0.008618402186731022\n",
      "25 50 -0.2653971314430237 0.0030355523194386374 0.008618954795528067\n",
      "25 55 -0.2488323152065277 0.0030355523194386374 0.00861965080439313\n",
      "valid_acc tensor(93.1767)\n",
      "best valid_acc tensor(93.1767)\n",
      "26 0 -0.22020867466926575 0.0030355523194386374 0.008620535233329828\n",
      "26 5 -0.20825599133968353 0.0030355523194386374 0.008621760576771888\n",
      "26 10 -0.28204184770584106 0.0030355523194386374 0.008622913323147172\n",
      "26 15 -0.2614084482192993 0.0030355523194386374 0.008624097811498747\n",
      "26 20 -0.2076815366744995 0.0030355523194386374 0.008625406242597312\n",
      "26 25 -0.18598447740077972 0.0030355523194386374 0.008626746952601034\n",
      "26 30 -0.23787370324134827 0.0030355523194386374 0.008628181201257645\n",
      "26 35 -0.2270689755678177 0.0030355523194386374 0.008629765661146638\n",
      "26 40 -0.23538847267627716 0.0030355523194386374 0.008631272199361098\n",
      "26 45 -0.21851752698421478 0.0030355523194386374 0.008632631449811056\n",
      "26 50 -0.213901087641716 0.0030355523194386374 0.008633910225280653\n",
      "26 55 -0.1958165019750595 0.0030355523194386374 0.008635146617771145\n",
      "valid_acc tensor(93.4433)\n",
      "best valid_acc tensor(93.4433)\n",
      "27 0 -0.23579439520835876 0.0030355523194386374 0.008636319397855793\n",
      "27 5 -0.243074432015419 0.0030355523194386374 0.008637323444945543\n",
      "27 10 -0.24125443398952484 0.0030355523194386374 0.008638314968417708\n",
      "27 15 -0.2330600768327713 0.0030355523194386374 0.008639275440295737\n",
      "27 20 -0.1820097714662552 0.0030355523194386374 0.008640369255384568\n",
      "27 25 -0.18999291956424713 0.0030355523194386374 0.008641488275572881\n",
      "27 30 -0.23006671667099 0.0030355523194386374 0.008642360902197757\n",
      "27 35 -0.2344273179769516 0.0030355523194386374 0.00864310705280102\n",
      "27 40 -0.23044489324092865 0.0030355523194386374 0.008643802212516953\n",
      "27 45 -0.2672933042049408 0.0030355523194386374 0.00864445458904154\n",
      "27 50 -0.22796416282653809 0.0030355523194386374 0.008645266060273604\n",
      "27 55 -0.22871194779872894 0.0030355523194386374 0.008646124526751257\n",
      "valid_acc tensor(93.4833)\n",
      "best valid_acc tensor(93.4833)\n",
      "28 0 -0.22581328451633453 0.0030355523194386374 0.008646932043889813\n",
      "28 5 -0.1882469803094864 0.0030355523194386374 0.008647591440559578\n",
      "28 10 -0.2194783240556717 0.0030355523194386374 0.00864819921798942\n",
      "28 15 -0.24149475991725922 0.0030355523194386374 0.008648838796298406\n",
      "28 20 -0.19407200813293457 0.0030355523194386374 0.00864924839018218\n",
      "28 25 -0.19296790659427643 0.0030355523194386374 0.008649654719278555\n",
      "28 30 -0.2467903047800064 0.0030355523194386374 0.008650036242973802\n",
      "28 35 -0.22183971107006073 0.0030355523194386374 0.008650408248087927\n",
      "28 40 -0.19259969890117645 0.0030355523194386374 0.00865055833153675\n",
      "28 45 -0.21744155883789062 0.0030355523194386374 0.008650625083046972\n",
      "28 50 -0.16102197766304016 0.003055482777909377 0.00865066112693317\n",
      "28 55 -0.196661576628685 0.003055482777909377 0.008650392501475668\n",
      "valid_acc tensor(93.6633)\n",
      "best valid_acc tensor(93.6633)\n",
      "29 0 -0.23908475041389465 0.003055482777909377 0.008649941613255352\n",
      "29 5 -0.2369888573884964 0.003055482777909377 0.008649404698049253\n",
      "29 10 -0.21842537820339203 0.003055482777909377 0.008648922274598703\n",
      "29 15 -0.20671218633651733 0.003055482777909377 0.00864865819267574\n",
      "29 20 -0.2225465178489685 0.003055482777909377 0.008648503832232885\n",
      "29 25 -0.16728228330612183 0.003055482777909377 0.008648419268009412\n",
      "29 30 -0.1886860430240631 0.003188775372218245 0.008648497288650248\n",
      "29 35 -0.21759337186813354 0.003188775372218245 0.008648760830251644\n",
      "29 40 -0.2138337939977646 0.003188775372218245 0.008648978844825106\n",
      "29 45 -0.20072555541992188 0.003188775372218245 0.008649138198484112\n",
      "29 50 -0.21792320907115936 0.003188775372218245 0.008649137738452592\n",
      "29 55 -0.24383583664894104 0.003188775372218245 0.00864923858477715\n",
      "valid_acc tensor(93.9183)\n",
      "best valid_acc tensor(93.9183)\n"
     ]
    }
   ],
   "source": [
    "#'''\n",
    "best_valid_acc = 0\n",
    "training_log = []\n",
    "for epoch in range(1, args.epochs):\n",
    "\n",
    "  # train loop\n",
    "  model.eval()\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    if args.cuda:\n",
    "      data, target = data.cuda(), target.cuda()\n",
    "    data, target = Variable(data), Variable(target)\n",
    "    \n",
    "    solutions = es.ask()\n",
    "    reward = np.zeros(es.popsize)\n",
    "    \n",
    "    for i in range(es.popsize):\n",
    "      update_model(solutions[i], model, model_shapes)\n",
    "      output = model(data)\n",
    "      loss = F.nll_loss(output, target)\n",
    "      reward[i] = - loss.item()\n",
    "\n",
    "    best_raw_reward = reward.max()\n",
    "    #reward = compute_centered_ranks(reward)\n",
    "    #l2_decay = compute_weight_decay(weight_decay_coef, solutions)\n",
    "    #reward += l2_decay\n",
    "\n",
    "    es.tell(reward)\n",
    "\n",
    "    result = es.result()\n",
    "    \n",
    "    if (batch_idx % 5 == 0):\n",
    "      print(epoch, batch_idx, best_raw_reward, result[0].mean(), result[3].mean())\n",
    "\n",
    "  curr_solution = es.current_param()\n",
    "  update_model(curr_solution, model, model_shapes)\n",
    "\n",
    "  valid_acc = evaluate(model, valid_loader, print_mode=False)\n",
    "  training_log.append([epoch, valid_acc])\n",
    "  print('valid_acc', valid_acc * 100.)\n",
    "  if valid_acc >= best_valid_acc:\n",
    "    best_valid_acc = valid_acc\n",
    "    best_model = copy.deepcopy(model)\n",
    "    print('best valid_acc', best_valid_acc * 100.)\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-e1ba295ddbc0>:8: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\n",
      "<ipython-input-8-aa6b7b8bbee1>:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average loss: 0.2052, Accuracy: 56351/60000 (93.9183%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9392)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(best_model, valid_loader, print_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-e1ba295ddbc0>:8: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\n",
      "<ipython-input-8-aa6b7b8bbee1>:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average loss: 0.1877, Accuracy: 9463/10000 (94.6300%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9463)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(best_model, test_loader, print_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-e1ba295ddbc0>:8: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\n",
      "<ipython-input-8-aa6b7b8bbee1>:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average loss: 0.2052, Accuracy: 56351/60000 (93.9183%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9392)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(best_model, train_loader, print_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_model(es.best_param(), model, model_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-e1ba295ddbc0>:8: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\n",
      "<ipython-input-8-aa6b7b8bbee1>:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average loss: 0.2173, Accuracy: 56223/60000 (93.7050%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9370)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, valid_loader, print_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-e1ba295ddbc0>:8: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\n",
      "<ipython-input-8-aa6b7b8bbee1>:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average loss: 0.2009, Accuracy: 9411/10000 (94.1100%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9411)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, test_loader, print_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-e1ba295ddbc0>:8: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\n",
      "<ipython-input-8-aa6b7b8bbee1>:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average loss: 0.2173, Accuracy: 56223/60000 (93.7050%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9370)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, train_loader, print_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_model(es.current_param(), model, model_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-e1ba295ddbc0>:8: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\n",
      "<ipython-input-8-aa6b7b8bbee1>:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average loss: 0.2052, Accuracy: 56351/60000 (93.9183%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9392)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, valid_loader, print_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-e1ba295ddbc0>:8: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\n",
      "<ipython-input-8-aa6b7b8bbee1>:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average loss: 0.1877, Accuracy: 9463/10000 (94.6300%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9463)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, test_loader, print_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-e1ba295ddbc0>:8: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\n",
      "<ipython-input-8-aa6b7b8bbee1>:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average loss: 0.2052, Accuracy: 56351/60000 (93.9183%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9392)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, train_loader, print_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-e1ba295ddbc0>:8: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\n",
      "<ipython-input-8-aa6b7b8bbee1>:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average loss: 0.1877, Accuracy: 9463/10000 (94.6300%)\n",
      "\n",
      "final test acc tensor(94.6300)\n"
     ]
    }
   ],
   "source": [
    "eval_acc = evaluate(best_model, test_loader)\n",
    "print('final test acc', eval_acc * 100.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 5, 5])\n",
      "torch.Size([8])\n",
      "torch.Size([16, 8, 5, 5])\n",
      "torch.Size([16])\n",
      "torch.Size([10, 784])\n",
      "torch.Size([10])\n",
      "11274\n"
     ]
    }
   ],
   "source": [
    "param_count = 0\n",
    "for param in model.parameters():\n",
    "  print(param.data.shape)\n",
    "  param_count += np.product(param.data.shape)\n",
    "print(param_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_params = []\n",
    "for param in orig_model.parameters():\n",
    "  orig_params.append(param.data.cpu().numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_params_flat = np.concatenate(orig_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.hist(orig_params_flat, bins=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_params = []\n",
    "for param in best_model.parameters():\n",
    "  final_params.append(param.data.cpu().numpy().flatten())\n",
    "final_params_flat = np.concatenate(final_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.hist(final_params_flat, bins=200)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
